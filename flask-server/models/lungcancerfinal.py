# -*- coding: utf-8 -*-
"""Lungcancerfinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUjnIwrN70gAG6Evpn5Z7T5D7aZV6oRL
"""

# Import necessary libraries
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.applications import EfficientNetB3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
from google.colab import files
import cv2
from IPython.display import display, HTML, clear_output
import ipywidgets as widgets
from google.colab import drive

drive.mount('/content/drive')
# Function to check dataset
def explore_dataset(dataset_path):
    class_folders = os.listdir(dataset_path)
    class_counts = {}
    sample_images = {}
    image_sizes = {}

    for class_folder in class_folders:
        folder_path = os.path.join(dataset_path, class_folder)
        if os.path.isdir(folder_path):
            images = os.listdir(folder_path)
            class_counts[class_folder] = len(images)

            # Sample some images and check their sizes
            sample_sizes = []
            for i, img_name in enumerate(images[:5]):
                img_path = os.path.join(folder_path, img_name)
                img = cv2.imread(img_path)
                if img is not None:
                    sample_sizes.append(img.shape)
                    if i == 0:
                        sample_images[class_folder] = img_path

            image_sizes[class_folder] = sample_sizes

    return class_counts, sample_images, image_sizes

# Set up paths
dataset_path = "/content/drive/MyDrive/The IQ-OTHNCCD lung cancer dataset"

# Explore dataset
class_counts, sample_images, image_sizes = explore_dataset(dataset_path)
print("Class distribution:")
for class_name, count in class_counts.items():
    print(f"- {class_name}: {count} images")

print("\nSample image sizes for each class:")
for class_name, sizes in image_sizes.items():
    print(f"- {class_name}: {sizes}")

# Define image dimensions for our model
# Based on the dataset exploration, we'll use a standard size that works well
IMAGE_HEIGHT = 224
IMAGE_WIDTH = 224
BATCH_SIZE = 32

# Data augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=False,
    fill_mode='nearest'
)

# Only rescaling for validation
valid_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Create data generators
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

validation_generator = valid_datagen.flow_from_directory(
    dataset_path,
    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# Get class mapping
class_indices = train_generator.class_indices
class_names = list(class_indices.keys())
print(f"Class indices: {class_indices}")

# Define and compile the model - Using EfficientNetB3 with transfer learning
def create_model():
    # Use EfficientNetB3 as base model with pretrained weights
    base_model = EfficientNetB3(
        weights='imagenet',
        include_top=False,
        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)
    )

    # Fine-tune the last few layers
    for layer in base_model.layers[:-30]:
        layer.trainable = False

    # Create model
    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.BatchNormalization(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(len(class_names), activation='softmax')
    ])

    # Compile the model
    model.compile(
        optimizer=optimizers.Adam(learning_rate=0.0001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

model = create_model()
model.summary()

# Callbacks for training
callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        filepath='lung_cancer_model_best.h5',
        save_best_only=True,
        monitor='val_accuracy',
        mode='max',
        verbose=1
    ),
    tf.keras.callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-6,
        verbose=1
    )
]

# Calculate steps
STEPS_PER_EPOCH = train_generator.samples // BATCH_SIZE
VALIDATION_STEPS = validation_generator.samples // BATCH_SIZE or 1

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=STEPS_PER_EPOCH,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=VALIDATION_STEPS,
    callbacks=callbacks,
    verbose=1
)

# Evaluate the model
val_loss, val_accuracy = model.evaluate(validation_generator)
print(f"Validation accuracy: {val_accuracy*100:.2f}%")

# If validation accuracy is less than 95%, we'll try another approach
if val_accuracy < 0.95:
    print("First attempt didn't reach 95% accuracy. Trying a different approach...")

    # Try a different approach: more aggressive data augmentation and deeper fine-tuning
    train_datagen_enhanced = ImageDataGenerator(
        rescale=1./255,
        validation_split=0.2,
        rotation_range=40,
        width_shift_range=0.3,
        height_shift_range=0.3,
        shear_range=0.3,
        zoom_range=0.3,
        horizontal_flip=True,
        vertical_flip=True,
        brightness_range=[0.8, 1.2],
        fill_mode='nearest'
    )

    train_generator_enhanced = train_datagen_enhanced.flow_from_directory(
        dataset_path,
        target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        subset='training',
        shuffle=True
    )

    # Create a new model with more fine-tuning
    base_model = EfficientNetB3(
        weights='imagenet',
        include_top=False,
        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)
    )

    # Fine-tune more layers
    for layer in base_model.layers[:-50]:
        layer.trainable = False

    model_enhanced = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.BatchNormalization(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.4),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(len(class_names), activation='softmax')
    ])

    # Compile with a lower learning rate
    model_enhanced.compile(
        optimizer=optimizers.Adam(learning_rate=0.00005),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # Train with more epochs and the enhanced data augmentation
    history_enhanced = model_enhanced.fit(
        train_generator_enhanced,
        steps_per_epoch=STEPS_PER_EPOCH,
        epochs=75,
        validation_data=validation_generator,
        validation_steps=VALIDATION_STEPS,
        callbacks=callbacks,
        verbose=1
    )

    # Evaluate the enhanced model
    val_loss_enhanced, val_accuracy_enhanced = model_enhanced.evaluate(validation_generator)
    print(f"Enhanced model validation accuracy: {val_accuracy_enhanced*100:.2f}%")

    # Choose the better model
    if val_accuracy_enhanced > val_accuracy:
        model = model_enhanced
        val_accuracy = val_accuracy_enhanced
        history = history_enhanced
        print("Using the enhanced model with higher accuracy.")
    else:
        print("Using the original model which had higher accuracy.")

# If we still haven't reached 95%, try a completely different architecture
if val_accuracy < 0.95:
    print("Still haven't reached 95% accuracy. Trying a different model architecture...")

    # Try Xception model which is often good with medical imaging
    from tensorflow.keras.applications import Xception

    base_model_xception = Xception(
        weights='imagenet',
        include_top=False,
        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)
    )

    # Freeze base model
    base_model_xception.trainable = False

    model_xception = models.Sequential([
        base_model_xception,
        layers.GlobalAveragePooling2D(),
        layers.BatchNormalization(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.4),
        layers.Dense(len(class_names), activation='softmax')
    ])

    # Compile with a different optimizer
    model_xception.compile(
        optimizer=optimizers.SGD(learning_rate=0.001, momentum=0.9),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # First train with frozen base
    history_xception_1 = model_xception.fit(
        train_generator_enhanced,
        steps_per_epoch=STEPS_PER_EPOCH,
        epochs=20,
        validation_data=validation_generator,
        validation_steps=VALIDATION_STEPS,
        verbose=1
    )

    # Now unfreeze and fine-tune the base model
    base_model_xception.trainable = True
    for layer in base_model_xception.layers[:-30]:
        layer.trainable = False

    # Recompile with a lower learning rate
    model_xception.compile(
        optimizer=optimizers.SGD(learning_rate=0.0001, momentum=0.9),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # Continue training with fine-tuning
    history_xception_2 = model_xception.fit(
        train_generator_enhanced,
        steps_per_epoch=STEPS_PER_EPOCH,
        epochs=50,
        validation_data=validation_generator,
        validation_steps=VALIDATION_STEPS,
        callbacks=callbacks,
        verbose=1
    )

    # Evaluate the Xception model
    val_loss_xception, val_accuracy_xception = model_xception.evaluate(validation_generator)
    print(f"Xception model validation accuracy: {val_accuracy_xception*100:.2f}%")

    # Choose the best model
    if val_accuracy_xception > val_accuracy:
        model = model_xception
        val_accuracy = val_accuracy_xception
        print("Using the Xception model with higher accuracy.")

# Save the final model
model.save('lung_cancer_final_model.h5')
print(f"Final model validation accuracy: {val_accuracy*100:.2f}%")

# Plot training history
def plot_history(history):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # Plot accuracy
    ax1.plot(history.history['accuracy'])
    ax1.plot(history.history['val_accuracy'])
    ax1.set_title('Model Accuracy')
    ax1.set_ylabel('Accuracy')
    ax1.set_xlabel('Epoch')
    ax1.legend(['Train', 'Validation'], loc='lower right')

    # Plot loss
    ax2.plot(history.history['loss'])
    ax2.plot(history.history['val_loss'])
    ax2.set_title('Model Loss')
    ax2.set_ylabel('Loss')
    ax2.set_xlabel('Epoch')
    ax2.legend(['Train', 'Validation'], loc='upper right')

    plt.tight_layout()
    plt.show()

plot_history(history)
# Generate confusion matrix
def plot_confusion_matrix():
    # Get predictions
    Y_pred = model.predict(validation_generator)
    y_pred = np.argmax(Y_pred, axis=1)

    # True labels
    y_true = validation_generator.classes

    # Generate confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Plot confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names,
                yticklabels=class_names)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')
    plt.show()

    # Print classification report
    print(classification_report(y_true, y_pred, target_names=class_names))


plot_confusion_matrix()

# Function to preprocess a single image for prediction
def preprocess_image(image_path):
    img = tf.keras.preprocessing.image.load_img(
        image_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH)
    )
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = img_array / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

# Function for prediction
def predict_image(image_path):
    preprocessed_img = preprocess_image(image_path)
    prediction = model.predict(preprocessed_img)
    predicted_class_index = np.argmax(prediction, axis=1)[0]
    predicted_class = list(class_indices.keys())[list(class_indices.values()).index(predicted_class_index)]
    confidence = prediction[0][predicted_class_index] * 100

    # Load and display image
    img = plt.imread(image_path)
    plt.figure(figsize=(6, 6))
    plt.imshow(img)
    plt.title(f'Prediction: {predicted_class} (Confidence: {confidence:.2f}%)')
    plt.axis('off')
    plt.show()

    # Print detailed results
    print(f"Prediction: {predicted_class}")
    print(f"Confidence: {confidence:.2f}%")
    print("\nDetailed probabilities:")
    for i, class_name in enumerate(class_names):
        print(f"{class_name}: {prediction[0][i]*100:.2f}%")

# Create interactive widgets for uploading and predicting
def upload_and_predict_button():
    upload_button = widgets.FileUpload(
        accept='image/*',
        multiple=False,
        description='Upload Chest X-ray'
    )

    output = widgets.Output()

    def on_upload_change(change):
        with output:
            clear_output()
            if upload_button.value:
                uploaded_file_info = next(iter(upload_button.value.values()))
                file_name = uploaded_file_info['metadata']['name']

                with open(file_name, 'wb') as f:
                    f.write(uploaded_file_info['content'])

                print(f"Analyzing image: {file_name}")
                predict_image(file_name)

    upload_button.observe(on_upload_change, names='value')
    display(widgets.VBox([upload_button, output]))

# Display the upload button
print("\n\nUpload an image for classification:")
upload_and_predict_button()

# Instructions for rerunning just the classification part
print("\n" + "-"*80)
print("INSTRUCTIONS FOR TESTING NEW IMAGES WITHOUT RETRAINING:")
print("-"*80)
print("To test a new image without retraining the model, run the following code:")
print("""
# Load the saved model
from tensorflow.keras.models import load_model
model = load_model('lung_cancer_final_model.h5')

# Display upload button
upload_and_predict_button()
""")
print("-"*80)

from tensorflow.keras.models import load_model
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from PIL import Image
import numpy as np
import io
from google.colab import files

# Upload an image
uploaded = files.upload()  # This opens a file upload dialog

# Load the trained model
model = load_model('/content/lung_cancer_model_best.h5')

# Get class names (update based on your model's classes)
class_names = ['BENGIN CASES', 'MALIGNANT CASES', 'NORMAL CASES']  # <-- Replace with your actual labels

# Preprocess and predict on uploaded image
for file_name in uploaded.keys():
    # Load and preprocess the image
    img = Image.open(io.BytesIO(uploaded[file_name])).convert('RGB')
    img = img.resize((224, 224))  # Resize to match model input
    img_array = img_to_array(img)
    img_array = preprocess_input(img_array)  # EfficientNet-specific preprocessing
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

    # Predict
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions)]

    # Output
    print(f"\nðŸ” Uploaded image: {file_name}")
    print(f"âœ… Predicted class: {predicted_class}")